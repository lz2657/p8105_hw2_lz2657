---
title: "p8105_hw2_lz2657"
author: Lingyu Zhang
date: Sep 30, 2018
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
devtools::install_github("p8105/p8105.datasets", force = TRUE)
library(tidyverse)
library(readxl)
library(p8105.datasets)
```

## Problem 1

First, read and clean the data as required.

```{r problem1_read_clean}
NYC_subway_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(entry=as.logical(ifelse(entry == 'YES', TRUE, FALSE)))
```

The dataset now contains variables of line, station name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. I read the original dataset, cleaned the names, selected the variables I need and convert the entry variable to logical by 'mutate' and 'ifelse' function.

The dimension of the dataset is `r nrow(NYC_subway_data)` x `r ncol(NYC_subway_data)`. The data is not tidy yet.

There are `r nrow(distinct(NYC_subway_data, line, station_name))` distinct stations. 

`r sum(NYC_subway_data$ada==1)` stations are ADA compliant. 

`r round(100*sum(NYC_subway_data$vending=='NO'&NYC_subway_data$entry==TRUE)/sum(NYC_subway_data$vending=='NO'), digits= 2)`% of station entrances / exits without vending allow entrance.

Then reformat the dataset.

```{r problem1_reformat}
NYC_subway_data = mutate(NYC_subway_data, route_number = rowSums(!is.na(select(NYC_subway_data, route1:route11)))) %>%
  unite(route_name, route1:route11, sep='/', remove = TRUE) %>%
  select(line:station_longitude, route_number, route_name, everything())

NYC_subway_data$route_name = gsub("/NA","",NYC_subway_data$route_name)

NYC_subway_data
```

There are `r sum((gsub("[^A]","",NYC_subway_data$route_name))=='A')` distinct stations serve the A train.

Of the stations that serve the A train, `r sum(gsub("[^A]","",NYC_subway_data$route_name)=='A'&NYC_subway_data$ada==TRUE)` are ADA compliant.



## Problem 2

First, read and clean the Mr. Trash Wheel sheet as required.

```{r problem2_trash_wheel}
trash_wheel_data = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(sports_balls=as.integer(round(sports_balls)))

trash_wheel_data
```

Then read and clean precipitation data for 2016 and 2017.

```{r problem2_2016}
precipitation_2016_data = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "2016 Precipitation", range = "A2:B14") %>%
  janitor::clean_names() %>%
  filter(!is.na(total)) %>%
  mutate(year = 2016) %>%
  select(year, month, total)

precipitation_2016_data
```

```{r problem2_2017}
precipitation_2017_data = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = "2017 Precipitation", range = "A2:B14") %>%
  janitor::clean_names() %>%
  filter(!is.na(total)) %>%
  mutate(year = 2017) %>%
  select(year, month, total)

precipitation_2017_data
```

Now combine datasets and convert month to a character variable.

```{r problem2_combine}
precipitation_data = full_join(precipitation_2016_data, precipitation_2017_data, by = NULL) %>%
  mutate(month = month.name[month])

precipitation_data
```

The Mr. Trash Wheel dataset includes 14 variables, including dumpster, date, weight, volume, sports_balls and so on. The number of observations is `r nrow(trash_wheel_data)`. The precipitation dataset includes three variables: year, month and total. It shows the precipitation data for each month in 2016 and 2017. The number of precipitations is `r nrow(precipitation_data)`. The total precipitation in 2017 is `r sum(ifelse((precipitation_data$year == 2017), precipitation_data$total, 0))`. The median number of sports balls in a dumpster in 2016 is `r median(subset(trash_wheel_data, year == 2016)$sports_balls)`.



## Problem 3

First, read and manipulate the data as required.

```{r problem3_read_manipulate}
data("brfss_smart2010")
brfss_data = brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  select(-class, -topic, -question, -sample_size, -(confidence_limit_low:geo_location)) %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>%
  select(year, locationabbr, locationdesc, excellent, very_good, good, fair, poor) %>%
  mutate(proportion = excellent + very_good)

brfss_data
```